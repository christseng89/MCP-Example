# Course Recap 🌏 Chinese Translation

**恭喜你！**

你做到了。
你堅持完成了這門課程，我百分之百確信你已經學到了很多。

我們從基礎開始，現在你已經清楚了解什麼是 **模型上下文協議（Model Context Protocol, MCP）**。
請記住：MCP 本質上是一層額外的抽象，用來讓 **客戶端** 連接到 **伺服器**。

這層抽象可以是 API 的封裝器，也可以包含 **資源（resources）** 和 **提示模板（prompt templates）**。
它讓切換客戶端變得非常簡單，標準化了 HTTP 請求，並且允許一個伺服器擁有許多不同的工具。透過 MCP，主機可以更輕鬆地處理 API 請求並提升效率。

如果 API 更新，MCP 很可能會自動支援更新。
很多公司都在開發 MCP 伺服器，因此你無需不斷修改成千上萬的 HTTP 請求即可接入。

我們還簡單談到了 **提示工程（Prompt Engineering）**。
請記住：最好的系統提示往往是最簡單的。如果必須使用系統提示，你現在也知道該怎麼做。
如果不確定如何與 AI 對話，你也可以參考 **Anthropic 的提示指南**。

在課程中，我們一步步實作：

* 安裝 **Node.js**、**Cloud Desktop** 和第一批 MVP 伺服器。
* 學會用單一或多個 config 文件配置 MCP。
* 使用 MCP Installer 讓安裝更方便。
* 安裝 **Python（pyenv）** 和 **nvm** 來管理 Python 與 Node.js 版本。
* 瞭解如何在 **GitHub** 找到官方 MCP 工具，並配置 API Key 與整合。

我們還研究了 **Cursor IDE**：

* 安裝並配置。
* 為 Cursor 加入 MCP 支援（它也能作為一個 host）。
* 目前的限制是還沒有內建提示和資源。

接著我們討論了 **插件（Addons）**：

* 可以本地部署，或放在 Render、Hostinger，甚至 Nedan 雲端方案上。
* 選定後開始建立工作流：觸發器 + 動作、伺服器 + 客戶端，以及 AI 代理整合。
* 學會使用 **社群節點** 連接 GitHub 上的伺服器。

接下來是 **FlowiseAI**：

* 一個基於 LangChain 生態系統的拖拉式 UI。
* 完全開源，可自託管或本地安裝。
* 適合建立代理、聊天流、應用程式與網頁整合。
* 內建許多預先構建的 MCP。

我們還探索了 **進階工作流**：

* 語音整合。
* 自動化 Blender 流程。
* 儲存與回憶記憶的 AI 代理 / MCP 伺服器。
* 透過 Webhook 生成圖片、聲音或影片。

最後，我們 **自己動手建立 MCP 伺服器**：

* 使用 Python SDK（或 TypeScript）。
* 從小開始：新建資料夾 → 描述伺服器 → 檢查程式碼 → 在 MCP Inspector 測試。
* 成功後再逐步擴展：加入資源、提示模板、更多工具。
* 但要記住：工具太多（20、30、50…）會讓 LLM 難以判斷該調用哪一個。

我們也討論了 **通訊方式**（stdio、streamable HTTP、SSE）以及 **部署選項**（AWS、Azure、Render、Hostinger）。

當然，**安全性至關重要**：
請務必加上身份驗證，確保合規，不要隨便連接陌生伺服器。

---

最後，我真心想對你說一句：**謝謝你！**
時間是最寶貴的資源，而你選擇將它投入到這門課程，這對我意義重大。

我相信我們還會在其他課程再次相遇，或者在這門課程的更新中重逢。
如果你覺得這門課程對你有幫助，請分享給你的朋友——我相信他們也會很感激。

下次再見！

---
